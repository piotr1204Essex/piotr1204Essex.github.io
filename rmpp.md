---
layout: research_methods
title: Research Methods
---

## Collaborative discussions
### Collaborative Learning Discussion 1
#### Initial post
I have chosen to review the Malicious Inputs to Content Filters case (Case: Malicious inputs to content filters, 2018). Blocker Plus serves, in my opinion, a crucial role in children’s safety when browsing the internet. It is intended to block the content that is legally protected by the U.S. Children’s Internet Protection Act (CIPA, 2000).

The issue at hand is that the machine learning based algorithm started to block the content that was not explicitly prohibited by the CIPA. Which raises a question: what has caused such behaviour? The algorithm was intentionally misled by a group of people acting with a purpose such that specific information was parsed to the algorithm in order to be marked as harmful for children. Amongst several topics being blocked, was information about gay and lesbian marriages. Not only was this topic not prohibited by CIPA, but it has also been found that age-appropriate sexual education is beneficial for children (Breuner et al., 2016).

This situation raises important questions related to legal and social issues as well as the professionalism of the Blocker Plus’ development team. One of the logical provisions of the law is that whatever is not forbidden, must be allowed. Looking from this angle, the development team would have done nothing wrong. This is where the ethics come in and why they are so important in computing professionals practice (and many others). The Blocker Plus, as indicated in the case study analysis, has failed to meet several ethics code principles. In essence, it has failed to provide sufficient security which in turn made the product not serve its intended purpose. With the products of such importance, which is protection of children from harmful content, one can argue that making such products work exactly as intended is a matter of the highest priority. 

The social impact of the issue, apart from distrust of the customers, can also be a delayed sexual education for children, which might have a negative effect on their knowledge about sexually transmitted diseases or increase the risks of adolescent pregnancy (Breuner et al., 2016).

The development team has failed to meet the ethics code principles, some of them being very similar to BCS Code of Conduct (BCS). For example, the aforementioned issue related to sexual education, violates rule number 1. of the public interest section, which states clearly that you shall have due regard for public health, privacy, security and wellbeing of others and the environment. Rule number 3. of the same section, clearly prohibits from discrimination. In the case of blocking gay and lesbian marriages information, it can constitute discrimination based on sexual orientation, which again, is against the BCS code of conduct. 

While I believe that none of the shortcomings Blocker Plus’ system had were put in there intentionally, it is the outcome that matters. Unfortunately the outcome was a material breach of several ethics code principles as well as BCS code of conduct. 

References:

- Case: Malicious inputs to content filters - ACM ethics (2018) ACM Ethics - The Official Site of the Association for Computing Machinery’s Committee on Professional Ethics. Available at: https://ethics.acm.org/code-of-ethics/using-the-code/case-malicious-inputs-to-content-filters/ (Accessed: 08 August 2023). 
- Children’s internet protection act (2000). 
- Breuner, C.C. et al. (2016) ‘Sexuality Education for Children and Adolescents’, Pediatrics, 138(2). doi:10.1542/peds.2016-1348. 
- BCS Code of conduct (no date) BCS. Available at: https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/ (Accessed: 08 August 2023).

### Unit 1 - Reflective Activity
